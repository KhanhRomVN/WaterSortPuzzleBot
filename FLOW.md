# Flow Training - Water Sort Puzzle AI

## üìã T·ªïng quan
Project s·ª≠ d·ª•ng **4-phase training**:
1. **Phase 1 (heuristic_solver.py)**: T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´ heuristic solver
2. **Phase 2 (imitation_learning.py)**: Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi Imitation Learning
3. **Phase 3 (self_play.py)**: T·∫°o d·ªØ li·ªáu self-play v·ªõi MCTS
4. **Phase 4 (reinforcement_learning.py)**: Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi d·ªØ li·ªáu self-play (AlphaZero)

---

## üîÑ PHASE 1: HEURISTIC SOLVER (heuristic_solver.py)

### 1. Heuristic Solver
- Thu·∫≠t to√°n: **Greedy Best-First Search** v·ªõi 8 heuristics
- T·ª∑ l·ªá gi·∫£i: **???%**
- T·∫°o expert demonstrations

### 2. Generate Training Data
- **5,000 games** (10 iterations √ó 500 games)
- **~50,000-100,000 samples** (state, action, value)
- M·ªói sample: `(state, policy_target, value_target)`

### 3. Output
- File: `heuristic_data.pkl` (ch·ª©a c√°c samples)

---

## üöÄ PHASE 2: IMITATION LEARNING (imitation_learning.py)

### 4. Load Training Data
- Load `heuristic_data.pkl` t·ª´ `PHASE 1`

### 5. Train Neural Network
- Thu·∫≠t to√°n: **Imitation Learning** (Behavioral Cloning)
- Loss: **Cross-entropy** (policy) + **MSE** (value)
- **200 epochs** (10 iter √ó 20 epochs)
- Optimizer: **Adam** (lr=0.001, weight_decay=1e-4)

### 6. Output
- File: `watersort_imitation.pth`
- Win rate: **??-??%**
- Training time: **30-45 ph√∫t**

---

## üîÅ PHASE 3: SELF-PLAY (self_play.py)

### 7. Load Pre-trained Model
- Load `watersort_imitation.pth` t·ª´ `PHASE 2`

### 8. Self-Play Loop
- **100 games** per iteration
- M·ªói game: MCTS search (**100 simulations**/move)
- Generate trajectories: `(state, œÄ, z)`
- Store v√†o **replay buffer** (max 10,000 samples)

### 9. Output
- File: `self_play_data.pkl` (ch·ª©a c√°c trajectories)

---

## üéØ PHASE 4: REINFORCEMENT LEARNING (reinforcement_learning.py)

### 10. Load Self-Play Data
- Load `self_play_data.pkl` t·ª´ `PHASE 3`

### 11. Train with Self-Play Data
- Loss: **KL divergence** (policy) + **MSE** (value)
- **10 epochs** per iteration
- Batch size: **32**
- Optimizer: **Adam** (lr=0.001 ho·∫∑c 0.0001 n·∫øu fine-tune)

### 12. Evaluation
- Test m·ªói **5 iterations**
- ƒêo win rate v√† average moves
- Save best model

### 13. Output
- File: `watersort_model.pth`
- Win rate: **90-100%**
- Training time: **10-20 gi·ªù** (100 iterations)

---

**Author**: KhanhRomVN  
**GitHub**: [WaterSortPuzzleBot](https://github.com/KhanhRomVN/WaterSortPuzzleBot)